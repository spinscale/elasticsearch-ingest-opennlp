import de.undercouch.gradle.tasks.download.Download

import org.elasticsearch.gradle.testclusters.StandaloneRestIntegTestTask
import org.gradle.api.tasks.Input;
import org.gradle.process.CommandLineArgumentProvider;

import java.nio.file.Files
import java.util.LinkedHashMap;
import java.util.Map;
import java.util.function.Supplier;
import java.util.stream.Collectors;

buildscript {
  dependencies {
    classpath "org.elasticsearch.gradle:build-tools:${elasticsearchVersion}"
  }
}

plugins {
  id "de.undercouch.download" version "4.1.1"
  // the old co.riiid.gradle is not gradle 7.0 compatible
  id "com.github.humblerookie.gradle" version "0.4.4"
  id "com.github.ben-manes.versions" version '0.33.0'
}

repositories {
  mavenCentral()
}

group = 'de.spinscale.elasticsearch.plugin.ingest'
version = "${elasticsearchVersion}.1-SNAPSHOT"

apply plugin: 'java'
apply plugin: 'idea'
apply plugin: 'elasticsearch.esplugin'
apply plugin: 'elasticsearch.testclusters'

sourceCompatibility = '11'

esplugin {
  licenseFile = rootProject.file('LICENSE.txt')
  noticeFile = rootProject.file('NOTICE.txt')
  name = 'ingest-opennlp'
  description = 'Ingest processor that uses OpenNLP for named entity extraction'
  classname = 'de.spinscale.elasticsearch.ingest.opennlp.IngestOpenNlpPlugin'
}

// remove me after alpha-2 release
configurations {
  resolveableCompileOnly {
    exclude(group: 'org.elasticsearch', module: 'elasticsearch-lz4')
  }
  implementation {
    exclude(group: 'org.elasticsearch', module: 'elasticsearch-lz4')
  }
}

githubRelease.doFirst {
  if (!System.getProperty('GITHUB_TOKEN', '')) {
    throw new Exception('Missing property GITHUB_TOKEN')
  }

  // check if zip file is there
  assert file("build/distributions/ingest-opennlp-${version}.zip").exists()

  // rename zip file
  def currentVersion = version.replace('-SNAPSHOT', '')
  def filename = "build/distributions/ingest-opennlp-${currentVersion}.zip"
  Files.copy(file("build/distributions/ingest-opennlp-${version}.zip").toPath(), file(filename).toPath())

  // configuration
  github {
    owner = 'spinscale'
    repo = 'elasticsearch-ingest-opennlp'
    token = System.getProperty('GITHUB_TOKEN')
    tagName = currentVersion
    assets = [ filename ]
    targetCommitish = 'main'
  }
}

// In this section you declare the dependencies for your production and test code
// Elasticsearch dependency is included due to the build-tools, test-framework as well
dependencies {
  implementation 'org.apache.opennlp:opennlp-tools:1.9.4'

  // the yaml tests require a log4j2 dependency, otherwise a dependency is thrown on startup
  runtimeOnly 'org.apache.logging.log4j:log4j-core:2.11.1'
}

testClusters.all {
  setting 'ingest.opennlp.model.file.names',     'en-ner-persons.bin'
  setting 'ingest.opennlp.model.file.locations', 'en-ner-locations.bin'
  setting 'ingest.opennlp.model.file.dates',     'en-ner-dates.bin'

  cliSetup 'ingest-opennlp/download-models'
}

// ignore javadoc errors for now
tasks.withType(Javadoc) {
  options.addStringOption('Xdoclint:none', '-quiet')
}

// download the models before the tests are run, also needed for packaging
project.afterEvaluate {
  processTestResources.dependsOn downloadModels
}

// download the models but dont overwrite existing ones
task downloadModels {
  doLast {
    downloadIfNotExists('http://opennlp.sourceforge.net/models-1.5/en-ner-person.bin',   'en-ner-persons.bin')
    downloadIfNotExists('http://opennlp.sourceforge.net/models-1.5/en-ner-location.bin', 'en-ner-locations.bin')
    downloadIfNotExists('http://opennlp.sourceforge.net/models-1.5/en-ner-date.bin',     'en-ner-dates.bin')
  }
}

def downloadIfNotExists(String url, String file) {
  String dir = rootDir.getAbsolutePath() + File.separator + 'src' + File.separator + 'test' + File.separator + 'resources' + File.separator + 'models'
  new File(dir).mkdirs()
  if (new File(dir + File.separator + file).exists() == false) {
    download {
      src url
      dest new File(dir, file)
    }
  }
}

// setup yaml rest tests
testClusters {
  yamlRestTest
}

sourceSets {
  yamlRestTest
}

configurations {
  yamlRestTestImplementation.extendsFrom testImplementation
  yamlRestTestRuntimeOnly.extendsFrom testRuntimeOnly
  restTestSpecs
}

tasks.register('copyRestTestSpecs', Copy) {
  from zipTree(configurations.restTestSpecs.singleFile)
  into "$buildDir/restResources/restspec"
}

TaskProvider<Zip> bundle = project.getTasks().withType(Zip.class).named("bundlePlugin");

// Register rest resources with source set
sourceSets.yamlRestTest.getOutput().dir("$buildDir/restResources/restspec");

tasks.register('yamlRestTest', StandaloneRestIntegTestTask) { testTask ->
    testTask.dependsOn(bundle, 'copyRestTestSpecs')

    def cluster = testClusters.yamlRestTest
    cluster.plugin(bundle.flatMap(AbstractArchiveTask::getArchiveFile))
    testTask.useCluster(testClusters.yamlRestTest)

    testTask.mustRunAfter(project.getTasks().named("test"))
    testTask.setTestClassesDirs(sourceSets.yamlRestTest.getOutput().getClassesDirs())
    testTask.setClasspath(sourceSets.yamlRestTest.getRuntimeClasspath())


    SystemPropertyCommandLineArgumentProvider nonInputProperties = new SystemPropertyCommandLineArgumentProvider()
    nonInputProperties.systemProperty("tests.rest.cluster", "${-> String.join(",", cluster.getAllHttpSocketURI())}")
    nonInputProperties.systemProperty("tests.cluster", "${-> String.join(",", cluster.getAllTransportPortURI())}")
    nonInputProperties.systemProperty("tests.clustername", "${-> cluster.getName()}")
    testTask.getJvmArgumentProviders().add(nonInputProperties)
    testTask.systemProperty("tests.rest.load_packaged", Boolean.FALSE.toString())
}

// this is a bit of a hack to make sure we run the test tests when releasing...
check.dependsOn 'yamlRestTest'

dependencies {
  yamlRestTestImplementation "org.elasticsearch.test:framework:$elasticsearchVersion"
  restTestSpecs "org.elasticsearch:rest-api-spec:$elasticsearchVersion"
}

// This will be available in 7.15 in build tools and not manually declared. 
public class SystemPropertyCommandLineArgumentProvider implements CommandLineArgumentProvider {
    private final Map<String, Object> systemProperties = new LinkedHashMap<>();

    public void systemProperty(String key, Supplier<String> value) {
        systemProperties.put(key, value);
    }

    public void systemProperty(String key, Object value) {
        systemProperties.put(key, value);
    }

    @Override
    public Iterable<String> asArguments() {
        return systemProperties.entrySet()
            .stream()
            .map(
                entry -> "-D"
                    + entry.getKey()
                    + "="
                    + (entry.getValue() instanceof Supplier ? ((Supplier) entry.getValue()).get() : entry.getValue())
            )
            .collect(Collectors.toList());
    }

    // Track system property keys as an input so our build cache key will change if we add properties but values are still ignored
    @Input
    public Iterable<String> getPropertyNames() {
        return systemProperties.keySet();
    }
}
